{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Data Preparation for Modeling\n",
    "----\n",
    "\n",
    "### Objective \n",
    "1. Glue ETL로 수행 이후 S3에 파티션되어 저장된 데이터들을 통합 후에 학습셋/검증셋으로 분리하여 S3에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib\n",
    "!pip install xgboost\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "feature_dir_name = 'modeling-feature-190808'     \n",
    "bucket = 'analytics-preprocessed-daekeun'    # s3 bucket name\n",
    "prefix_source = 'homecredit/train-csv'    # source directory\n",
    "prefix_target = 'homecredit/{}'.format(feature_dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Region과 IAM Role을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('us-west-2', 'arn:aws:iam::143656149352:role/service-role/AmazonSageMaker-ExecutionRole-20190803T155872')\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "region = boto3.Session().region_name\n",
    "role = get_execution_role() # get_execution_role() function is to search IAM role\n",
    "print((region, role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Data Loading and Transformation\n",
    "----\n",
    "- S3에 파티션되어 저장된 데이터들을 하나의 Pandas DataFrame으로 통합합니다. 데모에선 편의상 `pd.concat()`으로 여러 리스트들을 불러온 후 oncatenation을 수행하였지만, 이 방법은 매번 리스트를 새로 생성하므로 불필요한 메모리 낭비가 발생한다는 점을 주의하세요.\n",
    "- Binary Classification은 Supervisied Learning이므로 feature와 label를 분리합니다 (X and y). **`sk_id_curr` 컬럼은 고객의 고유 id로 학습 시에 불필요하므로 제거해야 합니다.**\n",
    "- 결측값들을 모두 0으로 대체합니다. 본 데모에선 편의상 0으로 간단하게 대체하였지만, 데이터 특성과 각 컬럼의 결측치 분포에 따라 적절한 결측치 채움 기법을(imputation) 적용하는 것을 권장합니다. \n",
    "    - 참조: https://scikit-learn.org/stable/modules/impute.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 5.47 s, total: 22.3 s\n",
      "Wall time: 55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "objs = []\n",
    "response = s3.list_objects(Bucket = bucket, Prefix = prefix_source)\n",
    "\n",
    "for obj in response['Contents']:\n",
    "    objs.append(obj['Key'])\n",
    "\n",
    "train_df = pd.concat([pd.read_csv('s3://' + bucket + '/' + obj) for obj in objs[1:]])\n",
    "\n",
    "X = train_df.copy()\n",
    "X.drop(['sk_id_curr', 'target'], axis=1, inplace=True)\n",
    "y = train_df['target'].copy()\n",
    "X.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((306020, 376), (306020, 374), (306020,))\n"
     ]
    }
   ],
   "source": [
    "print((train_df.shape, X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dir_local = 'trnval'\n",
    "\n",
    "if not os.path.exists(feature_dir_local):\n",
    "    os.mkdir(feature_dir_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. K-fold Split and Save\n",
    "----\n",
    "- 데이터를 학습 데이터와 검증 데이터로 분리하여 libsvm 포맷으로 로컬에 저장 후, S3로 업로드합니다.\n",
    "    - Stratified K-Fold(층화추출)로 fold를 생성합니다. 이 방법은 특정 fold에 특정 class가 몰리는 현상을 방지할 수 있기에 불균형 데이터(imbalanced dataset)의 검증에 적절합니다.\n",
    "    - Sagemaker의 XGBoost에서 지원하는 입력 데이터 포맷은 *text/libsvm*(Default) 또는 *text/csv* 입니다.\n",
    "    - libsvm포맷의 각 열은 `<label> <index0>:<value0> <index1>:<value1> ...` 형식으로 저장되며 binary 포맷은 아니지만, csv 파일 대비 용량을 절약할 수 있습니다.\n",
    "- 본 데모에선 편의상 하나의 fold만 저장합니다. 만약 모든 fold를 저장하고 싶다면 `if fold_ == 0:`을 주석처리하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split, ShuffleSplit\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save features for XGBoost, a built-in algorithm in Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Dumping fold_0 to local\n",
      "\t XGBoost train_path=trnval/train.libsvm \n",
      "\t XGBoost valid_path=trnval/valid.libsvm\n",
      "---> Saving fold_0 to s3 bucket\n",
      "\t S3 train_path=homecredit/modeling-feature-190808/train.libsvm \n",
      "\t S3 valid_path=homecredit/modeling-feature-190808/valid.libsvm\n",
      "CPU times: user 2min 8s, sys: 5.03 s, total: 2min 13s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X.values, y.values)):\n",
    "    if fold_ == 0:    \n",
    "        # split training data and validation data\n",
    "        trn_data, trn_y = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "        val_data, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        # save features to local     \n",
    "        print('---> Dumping fold_{} to local'.format(fold_))\n",
    "        trn_path_local = os.path.join(feature_dir_local, 'train.libsvm')\n",
    "        val_path_local = os.path.join(feature_dir_local, 'valid.libsvm')  \n",
    "        print('\\t XGBoost train_path={} \\n\\t XGBoost valid_path={}'.format(trn_path_local, val_path_local))\n",
    "\n",
    "        dump_svmlight_file(X=trn_data, y=trn_y, f=trn_path_local)\n",
    "        dump_svmlight_file(X=val_data, y=val_y, f=val_path_local)\n",
    "\n",
    "        # upload to amazon s3\n",
    "        print('---> Saving fold_{} to s3 bucket'.format(fold_))\n",
    "        trn_path_s3 = os.path.join(prefix_target, 'train.libsvm')\n",
    "        val_path_s3 = os.path.join(prefix_target, 'valid.libsvm')\n",
    "        print('\\t S3 train_path={} \\n\\t S3 valid_path={}'.format(trn_path_s3, val_path_s3))    \n",
    "\n",
    "        boto3.Session().resource('s3').Bucket(bucket).Object(trn_path_s3).upload_file(trn_path_local)\n",
    "        boto3.Session().resource('s3').Bucket(bucket).Object(val_path_s3).upload_file(val_path_local)\n",
    "        \n",
    "        # for checking prediction results using local model, instead of sagemaker container\n",
    "        joblib.dump((trn_data, val_y), os.path.join(feature_dir_local, 'train.pkl'))\n",
    "        joblib.dump((val_data, trn_y), os.path.join(feature_dir_local, 'valid.pkl'))             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save features for LightGBM\n",
    "- LightGBM은 Binary 포맷으로 변환 가능하여 용량을 대폭 줄일 수 있습니다. 아래 python code snippet을 참조해 주세요.\n",
    "```\n",
    "trn_lgb = lgb.Dataset(trn_data, label=trn_y)\n",
    "trn_lgb.save_binary(YOUR_PATH)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Dumping fold_0 to local\n",
      "\t LightGBM train_path=trnval/train.bin \n",
      "\t LightGBM valid_path=trnval/valid.bin\n",
      "---> Saving fold_0 to s3 bucket\n",
      "\t S3 train_path=homecredit/modeling-feature-190808/train.bin \n",
      "\t S3 valid_path=homecredit/modeling-feature-190808/valid.bin\n",
      "CPU times: user 17.3 s, sys: 2.83 s, total: 20.1 s\n",
      "Wall time: 8.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm as lgb\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X.values, y.values)):\n",
    "    if fold_ == 0:    \n",
    "        # split training data and validation data\n",
    "        trn_data, trn_y = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "        val_data, val_y = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        # save features to local     \n",
    "        print('---> Dumping fold_{} to local'.format(fold_))\n",
    "        trn_path_local = os.path.join(feature_dir_local, 'train.bin')\n",
    "        val_path_local = os.path.join(feature_dir_local, 'valid.bin')  \n",
    "        print('\\t LightGBM train_path={} \\n\\t LightGBM valid_path={}'.format(trn_path_local, val_path_local))\n",
    "\n",
    "        trn_lgb = lgb.Dataset(trn_data, label=trn_y)\n",
    "        val_lgb = lgb.Dataset(val_data, label=val_y)\n",
    "        \n",
    "        trn_lgb.save_binary(trn_path_local)\n",
    "        val_lgb.save_binary(val_path_local)\n",
    "\n",
    "        # upload to amazon s3\n",
    "        print('---> Saving fold_{} to s3 bucket'.format(fold_))\n",
    "        trn_path_s3 = os.path.join(prefix_target, 'train.bin')\n",
    "        val_path_s3 = os.path.join(prefix_target, 'valid.bin')\n",
    "        print('\\t S3 train_path={} \\n\\t S3 valid_path={}'.format(trn_path_s3, val_path_s3))    \n",
    "\n",
    "        boto3.Session().resource('s3').Bucket(bucket).Object(trn_path_s3).upload_file(trn_path_local)\n",
    "        boto3.Session().resource('s3').Bucket(bucket).Object(val_path_s3).upload_file(val_path_local)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
